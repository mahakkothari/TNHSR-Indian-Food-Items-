{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PS_FINAL_MODEL_QUANT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "50jsFopsLgzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "f8cea14c-4f4c-4e46-d10a-0d4260168e75"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kyvndppLzOF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a9adf84-3efb-4d5c-8d8e-9b1ca0b83d95"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y9IaOi6LjJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(horizontal_flip= True, brightness_range = [0.7,1.3],validation_split=0.20,rotation_range=90, rescale = 1.0/255.0)\n",
        "valid_datagen = ImageDataGenerator(validation_split=0.20,rescale = 1.0/255.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gzakb690LwF7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "646a4bc9-43fe-4b47-dea8-c3601da11773"
      },
      "source": [
        "%cd ../content/drive/My Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAB9ggr_L6EL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5c17538-7d25-48a2-d20e-03387de77f0a"
      },
      "source": [
        "root = \"./images\"\n",
        "os.listdir(root)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kachori', 'Rice', 'Roti', 'Daal', 'Idli', 'Apple', 'Panner_Tikka', 'Banana']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ_2E5i6L78R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7a3ffef7-2cb1-48ab-cb9e-e9df19080204"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    root,\n",
        "    target_size=(512,512),\n",
        "    batch_size= 16,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_directory(\n",
        "    root, # same directory as training data\n",
        "    target_size=(512,512),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='validation') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2124 images belonging to 8 classes.\n",
            "Found 525 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn30ksU2L9g7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "bbe1d18d-22ab-47af-a1c8-c7c191eee985"
      },
      "source": [
        "!pip install efficientnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading https://files.pythonhosted.org/packages/28/91/67848a143b54c331605bfba5fd31cf4e9db13d2e429d103fe807acc3bcf4/efficientnet-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.12.0)\n",
            "Installing collected packages: efficientnet\n",
            "Successfully installed efficientnet-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csWCyzPoOUGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b63cdc22-e303-41d8-8925-4926669a2eba"
      },
      "source": [
        "import efficientnet.tfkeras as efn2\n",
        "model2=efn2.EfficientNetB6(weights='imagenet',include_top = False,input_shape=(512,512,3))\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b6_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "165527552/165527152 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajPKfz43OUCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWRIWUpqOT72",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ad8a2ad-166e-489c-80f8-bc6bde01241d"
      },
      "source": [
        "i=0\n",
        "for layer in model2.layers:\n",
        "  if(i>=655):\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "  i+=1\n",
        "print(i)\n",
        "model3 = Sequential([\n",
        "  model2,\n",
        "  Flatten(),\n",
        "  Dense(8, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32YwritYOQBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3.compile(loss='categorical_crossentropy', optimizer= 'Adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdqkKYjDO9Gn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "3dbb0cca-0e7d-4300-d6ba-3e0632a06e08"
      },
      "source": [
        "start = time.time()\n",
        "model3.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=2124//16,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=525//16)\n",
        "end = time.time()\n",
        "print('Processing time:',(end - start)/60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-101-7ae04c17f24d>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-101-7ae04c17f24d>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 63/132 [=============>................] - ETA: 2:23 - loss: 16.2198 - accuracy: 0.6464"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "132/132 [==============================] - ETA: 0s - loss: 13.8060 - accuracy: 0.7301"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 2. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r132/132 [==============================] - 327s 2s/step - loss: 13.8060 - accuracy: 0.7301 - val_loss: 5.7861 - val_accuracy: 0.9141\n",
            "Epoch 2/10\n",
            "132/132 [==============================] - 305s 2s/step - loss: 8.6763 - accuracy: 0.8567 - val_loss: 7.0839 - val_accuracy: 0.9316\n",
            "Epoch 3/10\n",
            "132/132 [==============================] - 304s 2s/step - loss: 7.0831 - accuracy: 0.8866 - val_loss: 7.2258 - val_accuracy: 0.9316\n",
            "Epoch 4/10\n",
            "132/132 [==============================] - 303s 2s/step - loss: 7.1095 - accuracy: 0.8923 - val_loss: 6.1519 - val_accuracy: 0.9395\n",
            "Epoch 5/10\n",
            "132/132 [==============================] - 303s 2s/step - loss: 5.2745 - accuracy: 0.9118 - val_loss: 6.2214 - val_accuracy: 0.9395\n",
            "Epoch 6/10\n",
            "132/132 [==============================] - 305s 2s/step - loss: 5.0602 - accuracy: 0.9198 - val_loss: 7.4717 - val_accuracy: 0.9355\n",
            "Epoch 7/10\n",
            "132/132 [==============================] - 305s 2s/step - loss: 4.8967 - accuracy: 0.9208 - val_loss: 6.8737 - val_accuracy: 0.9473\n",
            "Epoch 8/10\n",
            "132/132 [==============================] - 306s 2s/step - loss: 5.3092 - accuracy: 0.9227 - val_loss: 13.8797 - val_accuracy: 0.9082\n",
            "Epoch 9/10\n",
            "132/132 [==============================] - 305s 2s/step - loss: 4.7306 - accuracy: 0.9269 - val_loss: 9.0052 - val_accuracy: 0.9375\n",
            "Epoch 10/10\n",
            "132/132 [==============================] - 304s 2s/step - loss: 4.9597 - accuracy: 0.9388 - val_loss: 7.3254 - val_accuracy: 0.9551\n",
            "Processing time: 51.937736904621126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd0Bj4NXPV4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3.save('Food_rec.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umb66XEc03Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0WGBlge9mPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = tf.keras.models.load_model('Food_rec.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5P38ygLHYQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "cdc25fb2-0e2b-451c-8587-7021511c8903"
      },
      "source": [
        "model3.evaluate(validation_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 8/33 [======>.......................] - ETA: 30s - loss: 14.3556 - accuracy: 0.9375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "19/33 [================>.............] - ETA: 18s - loss: 8.4658 - accuracy: 0.9605"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 2. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "22/33 [===================>..........] - ETA: 14s - loss: 7.7610 - accuracy: 0.9602"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - 44s 1s/step - loss: 7.1440 - accuracy: 0.9562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7.143970012664795, 0.9561904668807983]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGawBG0gHYME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4oynduURZJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrwUjZIEGMo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model3)\n",
        "tflite_model = converter.convert()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oznzdsftG8oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl0HOVqKIz7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ae836a2-1603-4f4a-81e3-4106229f96b2"
      },
      "source": [
        "import pathlib\n",
        "tflite_models_dir = pathlib.Path(\"./PS_MODELS/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "tflite_model_file = tflite_models_dir/\"keras_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "181517328"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKa_2BoRJReJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cda286ff-1c26-44f5-d086-a0246a012504"
      },
      "source": [
        "import numpy as np\n",
        "for i in validation_generator:\n",
        "  print(np.shape(i[0]))\n",
        "  imag = i[0]\n",
        "  break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16, 512, 512, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAIAeB_9VdYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = tf.cast(imag, tf.float32) / 255.0\n",
        "mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
        "def representative_data_gen():\n",
        "  for input_value in mnist_ds.take(100):\n",
        "    yield [input_value]\n",
        "\n",
        "converter.representative_dataset = representative_data_gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMhfl6pnVhbF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdc382dd-384a-4ea4-afbc-2ed3d5fd20e5"
      },
      "source": [
        "tflite_model_quant = converter.convert()\n",
        "tflite_model_quant_file = tflite_models_dir/\"keras_model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_model_quant)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51323968"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqbUh1JzVlCH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a565fe06-c47c-41ca-fa9b-a0c181395109"
      },
      "source": [
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "tflite_model_quant = converter.convert()\n",
        "tflite_model_quant_file = tflite_models_dir/\"keras_model_quant_io.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_model_quant)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51323968"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHfsNN1FVtdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "interpreter_quant = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))\n",
        "interpreter_quant.allocate_tensors()\n",
        "input_index_quant = interpreter_quant.get_input_details()[0][\"index\"]\n",
        "output_index_quant = interpreter_quant.get_output_details()[0][\"index\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUAQx--QVxrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo8-jT_O75Xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=\"./PS_MODELS/keras_model_quant_io.tflite\")\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69qqD2E58L1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}